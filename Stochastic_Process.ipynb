{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravidox/hello-world/blob/main/Stochastic_Process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***DTMC PROBLEM STATEMENT***"
      ],
      "metadata": {
        "id": "QdTXugJnESiJ"
      },
      "id": "QdTXugJnESiJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRThW6ct-rdc"
      },
      "source": [
        "### **Problem Statement**\n",
        "\n",
        "a. Take input as the TPM for irreducible markov chain \n",
        "\n",
        "b. Find Steady State Behavior by solving equations.\n",
        "\n",
        "c. Simulate this for multiple runs\n",
        "\n",
        "d. Find behavior from the simulation perspective \n",
        "\n",
        "e. Identification of recurrent / transient states  and classes \n",
        "\n",
        "\n"
      ],
      "id": "qRThW6ct-rdc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbZQsnVhvXHR"
      },
      "source": [
        "### **Finding the Steady State Distribution: Linear Equations**"
      ],
      "id": "UbZQsnVhvXHR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear algebra method can be used to get the steady state. In this process we solve the linear equation Ax=x, where A is our TPM. The code below first takes input for our TPM and then solves for steady state."
      ],
      "metadata": {
        "id": "A17_HaGRCE_f"
      },
      "id": "A17_HaGRCE_f"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ac08e3f",
        "outputId": "eab76a88-4b10-4664-c0c8-1eb5cc51793c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows:3\n",
            "Number of columns:3\n",
            "Enter TPM \n",
            "0.2 0.6 0.2 0.5 0.4 0.1 0.2 0.3 0.5\n",
            "[[0.2 0.6 0.2]\n",
            " [0.5 0.4 0.1]\n",
            " [0.2 0.3 0.5]]\n",
            "Steady state [0.33333333 0.44444444 0.22222222]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np                                          \n",
        "from scipy.sparse import  eye, vstack\n",
        "from scipy.sparse.linalg import  spsolve\n",
        "\n",
        "R = int(input(\"Number of rows:\"))\n",
        "C = int(input(\"Number of columns:\"))\n",
        "print(\"Enter TPM \")\n",
        "entries = list(map(float, input().split()))\n",
        "matrix = np.array(entries).reshape(R, C)\n",
        "print(matrix)\n",
        "\n",
        "class markovChain(object): \n",
        "    \n",
        "    def __init__(self,P=None,direct=False):\n",
        "        self.P              = P \n",
        "        self.I             = None           \n",
        "\n",
        "    def fun(self): \n",
        "        s = P.shape[0]                \n",
        "        dP = P - eye(s)\n",
        "        v = vstack([np.ones(s), dP.T[1:]]).tocsr()  \n",
        "        z = np.zeros((s))\n",
        "        z[0] = 1      \n",
        "        self.I = spsolve(v, z)\n",
        "\n",
        "\n",
        "P = matrix\n",
        "m = markovChain(P)\n",
        "m.fun()\n",
        "print(\"Steady state\",m.I)\n"
      ],
      "id": "8ac08e3f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vjSFlIyJs7Z"
      },
      "source": [
        "### **Finding the Steady State Distribution : Matrix Multiplication**\n",
        " "
      ],
      "id": "0vjSFlIyJs7Z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix multiplication is another method to calculate Steady state. In this we multiply our TPM with an initial matrix and keeps on multiplying the matrix to get a steady state."
      ],
      "metadata": {
        "id": "CLyQwSnSE7_F"
      },
      "id": "CLyQwSnSE7_F"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fe51cec",
        "outputId": "7931677e-0cc6-4d3c-b376-43c5e839c51b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sationary probability distribution is:  [0.33333333 0.44444444 0.22222222]\n"
          ]
        }
      ],
      "source": [
        "steps = 10**6\n",
        "\n",
        "A_n = P\n",
        "\n",
        "i = 0\n",
        "while i < steps: \n",
        "    A_n = np.matmul(A_n, P)\n",
        "    i = i + 1\n",
        "\n",
        "print(\"The sationary probability distribution is: \", A_n[0])"
      ],
      "id": "9fe51cec"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwsPECbbtvT0"
      },
      "source": [
        "### **Defining the States in a Markov Chain**"
      ],
      "id": "QwsPECbbtvT0"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vgplb7qtsoL",
        "outputId": "67c34506-986e-4bdb-baea-8522ef67d691"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'STATE 1', 1: 'STATE 2', 2: 'STATE 3'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "state = { 0 : \"STATE 1\",\n",
        "          1 : \"STATE 2\", \n",
        "          2 : \"STATE 3\"\n",
        "        } \n",
        "state"
      ],
      "id": "1Vgplb7qtsoL"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p9IuO8luWhN",
        "outputId": "42561568-bcdf-43e3-a77b-a2a26d6eb92c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.2 0.6 0.2]\n",
            " [0.5 0.4 0.1]\n",
            " [0.2 0.3 0.5]]\n"
          ]
        }
      ],
      "source": [
        "A =matrix\n",
        "print(A)"
      ],
      "id": "0p9IuO8luWhN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24-z0prVufNU"
      },
      "source": [
        "###**Markov Chain as a Random Walk**\n",
        "To understand how a Markov process works an example of a Markov Process is shown here - Random Walk. This random walk shows the path of the Markov chain for 12 steps.      "
      ],
      "id": "24-z0prVufNU"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcHTg9UHuvff",
        "outputId": "233e02cd-51ff-4456-98ea-ba92e7558996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STATE 1 ----> STATE 1 ----> STATE 3 ----> STATE 1 ----> STATE 2 ----> STATE 1 ----> STATE 2 ----> STATE 2 ----> STATE 2 ----> STATE 3 ----> STATE 2 ----> STATE 2 ----> stop\n"
          ]
        }
      ],
      "source": [
        "n = 12\n",
        "\n",
        "start_state = 0\n",
        "print(state[start_state], \"---->\", end = \" \")\n",
        "previous_state = start_state \n",
        "\n",
        "while n > 1:\n",
        "    current_state = np.random.choice([0,1,2], p = A[previous_state])\n",
        "    print(state[current_state], \"---->\", end = \" \")\n",
        "    current_state = previous_state\n",
        "    n = n - 1 \n",
        "print(\"stop\")"
      ],
      "id": "mcHTg9UHuvff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH7IBitsu1p7"
      },
      "source": [
        "### **Simulation : Monte Carlo Method** \n",
        "\n",
        "Monte Carlo Simulation is a statistical technique which involves repeated random sampling baseed on some probability distribution to find out empirical probability (relative frequncy approach of probability). hence, we use Monte Carlo simulation here to find out how many times a process is in a particular state based on which the steady state distribution is calculated. "
      ],
      "id": "EH7IBitsu1p7"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44dc7829",
        "outputId": "46f33192-a64b-4bae-9768-3561964c87a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The stationary probability distribution is :  [0.333273 0.444349 0.222379]\n"
          ]
        }
      ],
      "source": [
        "steps = 10**6\n",
        "start_state = 2 \n",
        "pi = np.array([0, 0, 0])\n",
        "pi[start_state] = 1\n",
        "previous_state = start_state \n",
        "\n",
        "i = 0\n",
        "\n",
        "while i < steps: \n",
        "    current_state = np.random.choice([0,1,2], p = A[previous_state])\n",
        "    pi[current_state] = pi[current_state] + 1\n",
        "    previous_state = current_state \n",
        "    i = i + 1\n",
        "    \n",
        "print(\"The stationary probability distribution is : \", pi/steps)"
      ],
      "id": "44dc7829"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOovKTik6euA"
      },
      "source": [
        "### **Comparison of steady state**\n",
        "\n",
        "Here, the steady state distribution calculated by all three methods is displayed. As it is observed, Linear equation and matrix multiplication method gives an exact, accurate answer while Monte carlo simulation provides a approximate solution which is very close to the theoretical answer. \n",
        "\n",
        "\n"
      ],
      "id": "IOovKTik6euA"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwy3tlzaI1E5",
        "outputId": "a6d73dc2-731b-477f-d5a8-a84c1fe8e6c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear method:  [0.33333333 0.44444444 0.22222222] \n",
            "\n",
            "Matrix Multiplication [0.33333333 0.44444444 0.22222222] \n",
            "\n",
            "Monte Carlo Simulation [0.333273 0.444349 0.222379] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Linear method: \",m.I ,\"\\n\")\n",
        "print(\"Matrix Multiplication\",A_n[0],\"\\n\")\n",
        "print(\"Monte Carlo Simulation\",pi/steps,\"\\n\")"
      ],
      "id": "Cwy3tlzaI1E5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xlOvWaW1-T_"
      },
      "source": [
        "### **Transient and Recurrent States** "
      ],
      "id": "6xlOvWaW1-T_"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8TxAZ7_2FfX",
        "outputId": "3b4564d3-73bf-495c-a49c-012632426254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPM for irreducible markov Chain \n",
            " [[0.2 0.6 0.2]\n",
            " [0.5 0.4 0.1]\n",
            " [0.2 0.3 0.5]] \n",
            "\n",
            "Number of state :  {0: 'STATE 1', 1: 'STATE 2', 2: 'STATE 3'} \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Z= print(\"TPM for irreducible markov Chain \\n\",P,\"\\n\")\n",
        "print(\"Number of state : \", state, \"\\n\\n\")"
      ],
      "id": "T8TxAZ7_2FfX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuCg82PIATJy"
      },
      "source": [
        "\n",
        "As we are aware that an irreducible Markov chain with a finite state space\n",
        "is always recurrent because with a finite number of state it will move back\n",
        "to the same state in a long run. \n",
        "\n",
        "\n",
        "So, State 1,2,3 are all recurrent."
      ],
      "id": "KuCg82PIATJy"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Stochastic Process.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}